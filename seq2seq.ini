[strings]
# Mode : train, test, serve 运行模式
mode = train

# 处理后的中文数据集
seq_data = train_data/seq.data
train_data = train_data
# 训练集原始文件
resource_data = train_data/xiaohuangji50w_nofenci.conv

# 读取识别原始文件中段落和行头的标示
e = E
m = M

model_data = model_data
[ints]
# vocabulary size 
# 20,000 is a reasonable size
enc_vocab_size = 20000
dec_vocab_size = 20000
# embedding的维度，就是用多长的向量进行编码
embedding_dim = 128

# typical options : 128, 256, 512, 1024
# 神经元的数量
layer_size = 128
# dataset size limit; typically none : no limit
# 训练数据的最大值，当显存或内存不足时这样限制
max_train_data_size = 10000

batch_size = 32


